{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d8fc7d",
   "metadata": {},
   "source": [
    "# ğŸ¤– Synthetic Data Generator (SDG) - Multi-Agent System\n",
    "\n",
    "## ğŸ¯ Main Agent: Synthetic Data Generator\n",
    "\n",
    "**Purpose:** Generate realistic synthetic training images through a coordinated multi-agent pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ Agent Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   MAIN AGENT: SDG Orchestrator                  â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚  Sub-Agent 1: Prompt Analyzer                             â”‚ â”‚\n",
    "â”‚  â”‚  Input: User text description                             â”‚ â”‚\n",
    "â”‚  â”‚  Output: Parsed scene metadata (time, weather, location)  â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                         â”‚                                       â”‚\n",
    "â”‚                         â–¼                                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚  Sub-Agent 2: Scene Composer                              â”‚ â”‚\n",
    "â”‚  â”‚  Input: Scene metadata from Agent 1                       â”‚ â”‚\n",
    "â”‚  â”‚  Output: Base canvas with environment setup               â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                         â”‚                                       â”‚\n",
    "â”‚                         â–¼                                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚  Sub-Agent 3: Object Renderer                             â”‚ â”‚\n",
    "â”‚  â”‚  Input: Canvas + metadata from Agent 2                    â”‚ â”‚\n",
    "â”‚  â”‚  Output: Canvas with rendered objects (robots, vehicles)  â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                         â”‚                                       â”‚\n",
    "â”‚                         â–¼                                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚  Sub-Agent 4: Environmental Effects Agent                 â”‚ â”‚\n",
    "â”‚  â”‚  Input: Canvas with objects from Agent 3                  â”‚ â”‚\n",
    "â”‚  â”‚  Output: Canvas with weather & lighting effects           â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                         â”‚                                       â”‚\n",
    "â”‚                         â–¼                                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚  Sub-Agent 5: Post-Processing Agent                       â”‚ â”‚\n",
    "â”‚  â”‚  Input: Complete scene from Agent 4                       â”‚ â”‚\n",
    "â”‚  â”‚  Output: Final enhanced image + metadata                  â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                         â”‚                                       â”‚\n",
    "â”‚                         â–¼                                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚  Sub-Agent 6: Storage Manager                             â”‚ â”‚\n",
    "â”‚  â”‚  Input: Final image + metadata from Agent 5               â”‚ â”‚\n",
    "â”‚  â”‚  Output: Saved file + display confirmation                â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Execution Order\n",
    "\n",
    "**Run cells sequentially:**\n",
    "\n",
    "1. **Cell 1** - Configuration & Setup\n",
    "2. **Cell 2** - Dependencies Installation\n",
    "3. **Cell 3** - Sub-Agent 1: Prompt Analyzer\n",
    "4. **Cell 4** - Sub-Agent 2: Scene Composer\n",
    "5. **Cell 5** - Sub-Agent 3: Object Renderer\n",
    "6. **Cell 6** - Sub-Agent 4: Environmental Effects\n",
    "7. **Cell 7** - Sub-Agent 5: Post-Processor\n",
    "8. **Cell 8** - Sub-Agent 6: Storage Manager\n",
    "9. **Cell 9** - Main SDG Orchestrator (combines all agents)\n",
    "10. **Cell 10** - Interactive UI\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What Each Agent Does\n",
    "\n",
    "### ğŸ”§ Sub-Agent 1: Prompt Analyzer\n",
    "- **Input:** Raw text description from user\n",
    "- **Process:** NLP parsing to extract scene attributes\n",
    "- **Output:** Structured metadata (time, weather, location, objects)\n",
    "- **Example:** \"foggy street at night\" â†’ {time: \"night\", weather: \"fog\", location: \"street\"}\n",
    "\n",
    "### ğŸ¨ Sub-Agent 2: Scene Composer\n",
    "- **Input:** Metadata from Agent 1\n",
    "- **Process:** Creates base canvas, applies gradients, adds ground textures\n",
    "- **Output:** Base image with environment setup\n",
    "- **Example:** Night scene â†’ dark blue gradient + street texture\n",
    "\n",
    "### ğŸ¤– Sub-Agent 3: Object Renderer\n",
    "- **Input:** Canvas + object list from Agent 2\n",
    "- **Process:** Draws robots, vehicles, humans, packages with realistic details\n",
    "- **Output:** Canvas with all objects positioned and rendered\n",
    "- **Example:** Adds robot with gradient shading, camera arrays, wheels\n",
    "\n",
    "### ğŸŒ§ï¸ Sub-Agent 4: Environmental Effects\n",
    "- **Input:** Canvas with objects from Agent 3\n",
    "- **Process:** Applies weather effects (fog, rain, snow) and lighting\n",
    "- **Output:** Canvas with atmospheric effects and lighting\n",
    "- **Example:** Adds fog particles, street lamps, emergency lights\n",
    "\n",
    "### âœ¨ Sub-Agent 5: Post-Processor\n",
    "- **Input:** Complete scene from Agent 4\n",
    "- **Process:** Applies filters, enhances contrast/sharpness, adds overlays\n",
    "- **Output:** Final polished image + metadata list\n",
    "- **Example:** Smoothing, contrast boost, text overlays\n",
    "\n",
    "### ğŸ’¾ Sub-Agent 6: Storage Manager\n",
    "- **Input:** Final image + metadata from Agent 5\n",
    "- **Process:** Saves to disk, generates filename, creates display output\n",
    "- **Output:** Saved file + confirmation message\n",
    "- **Example:** Saves as `outputs/custom_scene_1234567890.png`\n",
    "\n",
    "### ğŸ¯ Main Agent: SDG Orchestrator\n",
    "- **Input:** User prompt from UI\n",
    "- **Process:** Coordinates all 6 sub-agents sequentially\n",
    "- **Output:** Complete synthetic image with full pipeline\n",
    "- **Example:** Manages entire flow from prompt â†’ final image\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Quick Start\n",
    "\n",
    "Run all cells in order (1â†’2â†’3â†’4â†’5â†’6â†’7â†’8â†’9â†’10), then use the interactive UI to generate images!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280e494",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 1: Configuration & API Setup\n",
    "\n",
    "**Agent:** System Configuration Agent\n",
    "\n",
    "**What it does:**\n",
    "- Sets up environment variables\n",
    "- Configures API keys (optional)\n",
    "- Initializes system settings\n",
    "\n",
    "**Input:** None (manual configuration)  \n",
    "**Output:** Configured environment ready for agents\n",
    "\n",
    "**Time:** Instant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614cc50",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 2: Dependency Manager Agent\n",
    "\n",
    "**Agent:** Dependency Installation & Setup Agent\n",
    "\n",
    "**What it does:**\n",
    "- Installs required Python packages\n",
    "- Imports libraries for all sub-agents\n",
    "- Creates output directories\n",
    "- Validates environment\n",
    "\n",
    "**Input:** System package manager  \n",
    "**Output:** All dependencies loaded and ready\n",
    "\n",
    "**Time:** 5-10 seconds (first run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d61acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key configured (optional)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key here (optional - only needed for Google Imagen API)\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCIzjoUfaDVPlTodHj0j3IWHI6QFqPFxl0\"\n",
    "\n",
    "print(\"âœ… API key configured (optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f85283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installing dependencies...\n",
      "âœ… All dependencies installed\n",
      "âœ… Output directory created: outputs/\n",
      "âœ… Ready to generate images!\n",
      "âœ… All dependencies installed\n",
      "âœ… Output directory created: outputs/\n",
      "âœ… Ready to generate images!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = ['pillow', 'ipywidgets']\n",
    "print(\"ğŸ“¦ Installing dependencies...\")\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Import all required libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "print(\"âœ… All dependencies installed\")\n",
    "print(\"âœ… Output directory created: outputs/\")\n",
    "print(\"âœ… Ready to generate images!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e851da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AGENT 1 (Prompt Analyzer) - Completed\n",
      "   Detected: Time=night, Weather=fog, Location=street\n",
      "   Objects: robot, vehicle\n",
      "\\nğŸ“Š Sample Output: {'time': 'night', 'weather': 'fog', 'location': 'street', 'objects': ['robot', 'vehicle'], 'colors': ['blue'], 'is_busy': False, 'has_emergency': False, 'has_safety_gear': False, 'original_prompt': 'A foggy street at night with a blue robot and cars'}\n"
     ]
    }
   ],
   "source": [
    "# SUB-AGENT 1: Prompt Analyzer\n",
    "# Parses user prompts and extracts scene metadata\n",
    "\n",
    "def prompt_analyzer_agent(user_prompt):\n",
    "    \"\"\"\n",
    "    Agent 1: Analyzes natural language prompt and extracts structured metadata\n",
    "    \n",
    "    Input: String (user description)\n",
    "    Output: Dictionary (scene metadata)\n",
    "    \"\"\"\n",
    "    \n",
    "    desc_lower = user_prompt.lower()\n",
    "    \n",
    "    # Time detection\n",
    "    time_of_day = \"day\"\n",
    "    if any(word in desc_lower for word in [\"night\", \"evening\", \"dusk\", \"twilight\", \"midnight\"]):\n",
    "        time_of_day = \"night\"\n",
    "    elif any(word in desc_lower for word in [\"sunset\", \"sunrise\", \"dawn\"]):\n",
    "        time_of_day = \"sunset\"\n",
    "    \n",
    "    # Weather detection\n",
    "    weather = \"clear\"\n",
    "    if any(word in desc_lower for word in [\"fog\", \"foggy\", \"mist\", \"misty\"]):\n",
    "        weather = \"fog\"\n",
    "    elif any(word in desc_lower for word in [\"rain\", \"rainy\", \"storm\", \"wet\"]):\n",
    "        weather = \"rain\"\n",
    "    elif any(word in desc_lower for word in [\"snow\", \"snowy\", \"blizzard\"]):\n",
    "        weather = \"snow\"\n",
    "    \n",
    "    # Location detection\n",
    "    location = \"urban\"\n",
    "    if any(word in desc_lower for word in [\"warehouse\", \"factory\", \"industrial\"]):\n",
    "        location = \"warehouse\"\n",
    "    elif any(word in desc_lower for word in [\"street\", \"road\", \"intersection\", \"highway\"]):\n",
    "        location = \"street\"\n",
    "    elif any(word in desc_lower for word in [\"parking\", \"lot\"]):\n",
    "        location = \"parking\"\n",
    "    \n",
    "    # Object detection\n",
    "    objects_detected = []\n",
    "    if any(word in desc_lower for word in [\"robot\", \"bot\", \"drone\"]):\n",
    "        objects_detected.append(\"robot\")\n",
    "    if any(word in desc_lower for word in [\"car\", \"vehicle\", \"truck\"]):\n",
    "        objects_detected.append(\"vehicle\")\n",
    "    if any(word in desc_lower for word in [\"human\", \"person\", \"worker\", \"pedestrian\"]):\n",
    "        objects_detected.append(\"human\")\n",
    "    if any(word in desc_lower for word in [\"package\", \"box\", \"parcel\"]):\n",
    "        objects_detected.append(\"package\")\n",
    "    if any(word in desc_lower for word in [\"cat\", \"dog\", \"animal\"]):\n",
    "        objects_detected.append(\"animal\")\n",
    "    \n",
    "    # Color detection\n",
    "    colors = []\n",
    "    for color in [\"yellow\", \"blue\", \"orange\", \"red\", \"green\"]:\n",
    "        if color in desc_lower:\n",
    "            colors.append(color)\n",
    "    \n",
    "    # Special attributes\n",
    "    is_busy = any(word in desc_lower for word in [\"busy\", \"crowded\"])\n",
    "    has_emergency = any(word in desc_lower for word in [\"emergency\", \"alarm\"])\n",
    "    has_safety_gear = any(word in desc_lower for word in [\"safety\", \"vest\"])\n",
    "    \n",
    "    metadata = {\n",
    "        \"time\": time_of_day,\n",
    "        \"weather\": weather,\n",
    "        \"location\": location,\n",
    "        \"objects\": objects_detected,\n",
    "        \"colors\": colors,\n",
    "        \"is_busy\": is_busy,\n",
    "        \"has_emergency\": has_emergency,\n",
    "        \"has_safety_gear\": has_safety_gear,\n",
    "        \"original_prompt\": user_prompt\n",
    "    }\n",
    "    \n",
    "    print(\"âœ… AGENT 1 (Prompt Analyzer) - Completed\")\n",
    "    print(f\"   Detected: Time={time_of_day}, Weather={weather}, Location={location}\")\n",
    "    print(f\"   Objects: {', '.join(objects_detected) if objects_detected else 'None'}\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Test the agent\n",
    "test_prompt = \"A foggy street at night with a blue robot and cars\"\n",
    "test_metadata = prompt_analyzer_agent(test_prompt)\n",
    "print(f\"\\\\nğŸ“Š Sample Output: {test_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecb554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AGENT 2 (Scene Composer) - Completed\n",
      "   Created: 1024Ã—576 canvas with street environment\n",
      "   Applied: night lighting, background gradients, ground textures\n",
      "\\nğŸ“Š Canvas created: (1024, 576)\n"
     ]
    }
   ],
   "source": [
    "# SUB-AGENT 2: Scene Composer\n",
    "# Creates base canvas with environment setup\n",
    "\n",
    "def scene_composer_agent(metadata):\n",
    "    \"\"\"\n",
    "    Agent 2: Composes base scene canvas using metadata from Agent 1\n",
    "    \n",
    "    Input: Dictionary (metadata from Agent 1)\n",
    "    Output: PIL Image (base canvas with gradients and textures)\n",
    "    \"\"\"\n",
    "    \n",
    "    width, height = 1024, 576\n",
    "    time_of_day = metadata[\"time\"]\n",
    "    weather = metadata[\"weather\"]\n",
    "    location = metadata[\"location\"]\n",
    "    \n",
    "    # Determine color scheme\n",
    "    if time_of_day == \"night\":\n",
    "        bg_color = (15, 20, 28) if location == \"warehouse\" else (25, 30, 45)\n",
    "        is_dark = True\n",
    "    elif time_of_day == \"sunset\":\n",
    "        bg_color = (180, 100, 60)\n",
    "        is_dark = False\n",
    "    elif weather == \"fog\":\n",
    "        bg_color = (165, 170, 175)\n",
    "        is_dark = False\n",
    "    else:\n",
    "        bg_color = (120, 150, 180)\n",
    "        is_dark = False\n",
    "    \n",
    "    # Create base image\n",
    "    img = Image.new('RGB', (width, height), color=bg_color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Apply gradient\n",
    "    for i in range(height):\n",
    "        alpha = i / height\n",
    "        noise = random.randint(-5, 5)\n",
    "        if is_dark:\n",
    "            r = int(bg_color[0] + 40 * alpha + noise)\n",
    "            g = int(bg_color[1] + 30 * alpha + noise)\n",
    "            b = int(bg_color[2] + 35 * alpha + noise)\n",
    "        else:\n",
    "            r = int(bg_color[0] + 30 * alpha + noise)\n",
    "            g = int(bg_color[1] + 20 * alpha + noise)\n",
    "            b = int(bg_color[2] + 15 * alpha + noise)\n",
    "        draw.line([(0, i), (width, i)], fill=(max(0, min(255, r)), max(0, min(255, g)), max(0, min(255, b))))\n",
    "    \n",
    "    # Add ground texture\n",
    "    if location == \"street\":\n",
    "        for _ in range(800):\n",
    "            x, y = random.randint(0, width), random.randint(height//2, height)\n",
    "            draw.rectangle([x, y, x+random.randint(2,6), y+1], \n",
    "                         fill=(60+random.randint(-10,10), 60+random.randint(-10,10), 65+random.randint(-10,10)))\n",
    "    elif location == \"warehouse\":\n",
    "        for _ in range(600):\n",
    "            x, y = random.randint(0, width), random.randint(height//2, height)\n",
    "            draw.rectangle([x, y, x+random.randint(1,4), y+1], \n",
    "                         fill=(35+random.randint(-5,5), 40+random.randint(-5,5), 45+random.randint(-5,5)))\n",
    "    \n",
    "    print(\"âœ… AGENT 2 (Scene Composer) - Completed\")\n",
    "    print(f\"   Created: {width}Ã—{height} canvas with {location} environment\")\n",
    "    print(f\"   Applied: {time_of_day} lighting, background gradients, ground textures\")\n",
    "    \n",
    "    return img, metadata\n",
    "\n",
    "# Test the agent (requires Agent 1 output)\n",
    "if 'test_metadata' in dir():\n",
    "    test_canvas, updated_metadata = scene_composer_agent(test_metadata)\n",
    "    print(f\"\\\\nğŸ“Š Canvas created: {test_canvas.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd21e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AGENT 3 (Object Renderer) - Completed\n",
      "   Rendered: ğŸ¤– Robot, ğŸš— 1 Vehicle(s)\n",
      "\\nğŸ“Š Objects rendered: ['ğŸ¤– Robot', 'ğŸš— 1 Vehicle(s)']\n"
     ]
    }
   ],
   "source": [
    "# SUB-AGENT 3: Object Renderer\n",
    "# Renders all objects on the canvas\n",
    "\n",
    "def object_renderer_agent(img, metadata):\n",
    "    \"\"\"\n",
    "    Agent 3: Renders objects on canvas using metadata from Agent 1\n",
    "    \n",
    "    Input: PIL Image (from Agent 2), Dictionary (metadata)\n",
    "    Output: PIL Image (canvas with objects), List (rendered elements)\n",
    "    \"\"\"\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "    objects_list = metadata.get(\"objects\", [])\n",
    "    colors_list = metadata.get(\"colors\", [])\n",
    "    is_busy = metadata.get(\"is_busy\", False)\n",
    "    has_safety_gear = metadata.get(\"has_safety_gear\", False)\n",
    "    elements_added = []\n",
    "    \n",
    "    # Render Robots/Drones\n",
    "    if \"robot\" in objects_list:\n",
    "        color = (255, 215, 0) if \"yellow\" in colors_list else \\\n",
    "                (255, 140, 0) if \"orange\" in colors_list else \\\n",
    "                (70, 130, 255) if \"blue\" in colors_list else (180, 180, 200)\n",
    "        \n",
    "        bot_x, bot_y = width//2, int(height * 0.55)\n",
    "        \n",
    "        # Robot body with gradient shading\n",
    "        for i in range(8):\n",
    "            shade = int(255 * (1 - i/10))\n",
    "            body_color = (int(color[0]*shade/255), int(color[1]*shade/255), int(color[2]*shade/255))\n",
    "            draw.rectangle([bot_x-100+i, bot_y-75+i, bot_x+100-i, bot_y+75-i], \n",
    "                         fill=body_color, outline=(color[0]//2, color[1]//2, color[2]//2), width=2)\n",
    "        \n",
    "        # Camera array\n",
    "        for i in range(3):\n",
    "            lens_x = bot_x - 50 + i * 50\n",
    "            draw.ellipse([lens_x-15, bot_y-40, lens_x+15, bot_y-10], \n",
    "                        fill=(40, 45, 60), outline=(80, 90, 120), width=3)\n",
    "        \n",
    "        # Status lights\n",
    "        for i in range(4):\n",
    "            light_x = bot_x - 60 + i * 40\n",
    "            draw.ellipse([light_x-5, bot_y+50, light_x+5, bot_y+60], fill=(0, 255, 100))\n",
    "        \n",
    "        # Wheels\n",
    "        for dx in [-70, 70]:\n",
    "            draw.ellipse([bot_x+dx-25, bot_y+60, bot_x+dx+25, bot_y+110], \n",
    "                       fill=(50, 50, 55), outline=(30, 30, 35), width=4)\n",
    "        \n",
    "        elements_added.append(\"ğŸ¤– Robot\")\n",
    "    \n",
    "    # Render Vehicles\n",
    "    if \"vehicle\" in objects_list:\n",
    "        num_vehicles = 3 if is_busy else 1\n",
    "        for v in range(num_vehicles):\n",
    "            car_x = 150 + v * 280\n",
    "            car_y = int(height * 0.65)\n",
    "            car_color = random.choice([(180, 0, 0), (0, 80, 180), (60, 60, 70)])\n",
    "            \n",
    "            # Car body with gradient\n",
    "            for i in range(5):\n",
    "                shade = (int(car_color[0]*(1-i*0.08)), int(car_color[1]*(1-i*0.08)), int(car_color[2]*(1-i*0.08)))\n",
    "                draw.rectangle([car_x+i, car_y+i, car_x+200-i, car_y+85-i], fill=shade)\n",
    "            \n",
    "            # Windows\n",
    "            draw.rectangle([car_x+30, car_y+15, car_x+80, car_y+50], fill=(120, 180, 220))\n",
    "            draw.rectangle([car_x+90, car_y+15, car_x+170, car_y+50], fill=(120, 180, 220))\n",
    "            \n",
    "            # Wheels\n",
    "            for wheel_x in [car_x+35, car_x+165]:\n",
    "                draw.ellipse([wheel_x-30, car_y+60, wheel_x+30, car_y+120], fill=(40, 40, 45))\n",
    "                draw.ellipse([wheel_x-20, car_y+70, wheel_x+20, car_y+110], fill=(60, 60, 65))\n",
    "        \n",
    "        elements_added.append(f\"ğŸš— {num_vehicles} Vehicle(s)\")\n",
    "    \n",
    "    # Render Humans\n",
    "    if \"human\" in objects_list:\n",
    "        num_people = 3 if is_busy else 1\n",
    "        for p in range(num_people):\n",
    "            worker_x = width - 200 - p * 80\n",
    "            worker_y = int(height * 0.60)\n",
    "            vest_color = (255, 200, 0) if has_safety_gear else (100, 120, 180)\n",
    "            \n",
    "            # Legs\n",
    "            draw.polygon([(worker_x-20, worker_y+50), (worker_x-15, worker_y+140), \n",
    "                         (worker_x-5, worker_y+140), (worker_x-8, worker_y+50)], fill=(40, 60, 90))\n",
    "            draw.polygon([(worker_x+8, worker_y+50), (worker_x+5, worker_y+140), \n",
    "                         (worker_x+15, worker_y+140), (worker_x+20, worker_y+50)], fill=(40, 60, 90))\n",
    "            \n",
    "            # Torso\n",
    "            for i in range(3):\n",
    "                shade_color = (int(vest_color[0]*(1-i*0.1)), int(vest_color[1]*(1-i*0.1)), int(vest_color[2]*(1-i*0.1)))\n",
    "                draw.rectangle([worker_x-35+i, worker_y-10+i, worker_x+35-i, worker_y+55-i], fill=shade_color)\n",
    "            \n",
    "            # Head\n",
    "            draw.ellipse([worker_x-28, worker_y-60, worker_x+28, worker_y-8], fill=(220, 180, 150))\n",
    "            \n",
    "            # Eyes\n",
    "            draw.ellipse([worker_x-15, worker_y-40, worker_x-8, worker_y-35], fill=(255, 255, 255))\n",
    "            draw.ellipse([worker_x+8, worker_y-40, worker_x+15, worker_y-35], fill=(255, 255, 255))\n",
    "        \n",
    "        elements_added.append(f\"ğŸ‘· {num_people} Person(s)\")\n",
    "    \n",
    "    # Render Packages\n",
    "    if \"package\" in objects_list:\n",
    "        num_packages = random.randint(5, 8)\n",
    "        for p in range(num_packages):\n",
    "            pkg_x = 100 + p * 60\n",
    "            pkg_y = int(height * 0.70) + random.randint(-20, 20)\n",
    "            pkg_size = random.randint(30, 50)\n",
    "            pkg_color = (150, 120, 80)\n",
    "            \n",
    "            # Package box\n",
    "            draw.rectangle([pkg_x, pkg_y, pkg_x+pkg_size, pkg_y+pkg_size], \n",
    "                         fill=pkg_color, outline=(100, 80, 50), width=2)\n",
    "            \n",
    "            # Tape\n",
    "            draw.line([(pkg_x, pkg_y+pkg_size//2), (pkg_x+pkg_size, pkg_y+pkg_size//2)], \n",
    "                     fill=(200, 180, 140), width=3)\n",
    "        \n",
    "        elements_added.append(f\"ğŸ“¦ {num_packages} Packages\")\n",
    "    \n",
    "    print(\"âœ… AGENT 3 (Object Renderer) - Completed\")\n",
    "    print(f\"   Rendered: {', '.join(elements_added) if elements_added else 'No objects'}\")\n",
    "    \n",
    "    return img, elements_added, metadata\n",
    "\n",
    "# Test the agent\n",
    "if 'test_canvas' in dir():\n",
    "    test_with_objects, test_elements, test_meta = object_renderer_agent(test_canvas, test_metadata)\n",
    "    print(f\"\\\\nğŸ“Š Objects rendered: {test_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a5104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AGENT 4 (Environmental Effects) - Completed\n",
      "   Applied: Weather=fog, Time=night\n",
      "   Effects: ğŸŒ«ï¸ Fog, ğŸŒ™ Night Lighting\n",
      "\\nğŸ“Š Effects applied: 4 total elements\n"
     ]
    }
   ],
   "source": [
    "# SUB-AGENT 4: Environmental Effects\n",
    "# Applies weather and lighting effects\n",
    "\n",
    "def environmental_effects_agent(img, elements_added, metadata):\n",
    "    \"\"\"\n",
    "    Agent 4: Applies environmental effects using metadata from Agent 1\n",
    "    \n",
    "    Input: PIL Image (from Agent 3), List (elements), Dictionary (metadata)\n",
    "    Output: PIL Image (canvas with effects), List (updated elements)\n",
    "    \"\"\"\n",
    "    \n",
    "    width, height = img.size\n",
    "    weather = metadata.get(\"weather\", \"clear\")\n",
    "    time_of_day = metadata.get(\"time\", \"day\")\n",
    "    has_emergency = metadata.get(\"has_emergency\", False)\n",
    "    \n",
    "    # Apply weather effects\n",
    "    if weather == \"fog\":\n",
    "        fog_layer = Image.new('RGBA', (width, height), (200, 200, 205, 0))\n",
    "        fog_draw = ImageDraw.Draw(fog_layer)\n",
    "        for _ in range(2000):\n",
    "            x, y = random.randint(0, width), random.randint(0, height)\n",
    "            radius = random.randint(30, 100)\n",
    "            fog_draw.ellipse([x-radius, y-radius, x+radius, y+radius], \n",
    "                           fill=(220, 220, 230, random.randint(10, 30)))\n",
    "        img = img.convert('RGBA')\n",
    "        img = Image.alpha_composite(img, fog_layer)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=4))\n",
    "        elements_added.append(\"ğŸŒ«ï¸ Fog\")\n",
    "        \n",
    "    elif weather == \"rain\":\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for _ in range(300):\n",
    "            x, y = random.randint(0, width), random.randint(0, height)\n",
    "            draw.line([(x, y), (x+3, y+random.randint(15, 30))], fill=(180, 190, 220), width=2)\n",
    "        elements_added.append(\"ğŸŒ§ï¸ Rain\")\n",
    "        \n",
    "    elif weather == \"snow\":\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for _ in range(600):\n",
    "            x, y = random.randint(0, width), random.randint(0, height)\n",
    "            size = random.randint(2, 5)\n",
    "            draw.ellipse([x, y, x+size, y+size], fill=(255, 255, 255))\n",
    "        elements_added.append(\"â„ï¸ Snow\")\n",
    "    \n",
    "    # Apply lighting effects\n",
    "    if time_of_day == \"night\":\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(0.6)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Street lamps\n",
    "        for i in range(4):\n",
    "            light_x = 200 + i * 250\n",
    "            draw.rectangle([light_x-8, 50, light_x+8, 150], fill=(80, 80, 85))\n",
    "            draw.ellipse([light_x-25, 20, light_x+25, 70], fill=(255, 240, 180))\n",
    "            \n",
    "            # Light cone\n",
    "            for j in range(30):\n",
    "                alpha = j / 30\n",
    "                cone_y = 70 + j * 15\n",
    "                cone_width = int(25 + j * 8)\n",
    "                light_color = (255, 240, 180, int(50 * (1-alpha)))\n",
    "        \n",
    "        elements_added.append(\"ğŸŒ™ Night Lighting\")\n",
    "        \n",
    "    elif time_of_day == \"sunset\":\n",
    "        sunset_overlay = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
    "        sunset_draw = ImageDraw.Draw(sunset_overlay)\n",
    "        for i in range(height//3):\n",
    "            alpha = int(60 * (1 - i/(height//3)))\n",
    "            sunset_draw.rectangle([0, i, width, i+1], fill=(255, 120, 50, alpha))\n",
    "        img = img.convert('RGBA')\n",
    "        img = Image.alpha_composite(img, sunset_overlay)\n",
    "        img = img.convert('RGB')\n",
    "        elements_added.append(\"ğŸŒ… Sunset\")\n",
    "    \n",
    "    # Emergency lights\n",
    "    if has_emergency:\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for i in range(3):\n",
    "            light_x = width//4 + i * width//4\n",
    "            light_y = 100\n",
    "            # Red emergency light glow\n",
    "            for r in range(20, 5, -2):\n",
    "                alpha = int(100 * (20-r)/20)\n",
    "                draw.ellipse([light_x-r, light_y-r, light_x+r, light_y+r], fill=(255, 0, 0))\n",
    "        elements_added.append(\"ğŸš¨ Emergency Lights\")\n",
    "    \n",
    "    print(\"âœ… AGENT 4 (Environmental Effects) - Completed\")\n",
    "    print(f\"   Applied: Weather={weather}, Time={time_of_day}\")\n",
    "    print(f\"   Effects: {', '.join([e for e in elements_added if e.startswith(('ğŸŒ«ï¸', 'ğŸŒ§ï¸', 'â„ï¸', 'ğŸŒ™', 'ğŸŒ…', 'ğŸš¨'))])}\")\n",
    "    \n",
    "    return img, elements_added, metadata\n",
    "\n",
    "# Test the agent\n",
    "if 'test_with_objects' in dir():\n",
    "    test_with_effects, test_elements_updated, test_meta = environmental_effects_agent(\n",
    "        test_with_objects, test_elements, test_metadata)\n",
    "    print(f\"\\\\nğŸ“Š Effects applied: {len(test_elements_updated)} total elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fe3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AGENT 5 (Post-Processor) - Completed\n",
      "   Applied: Smoothing, Contrast (1.15x), Sharpness (1.2x)\n",
      "   Added: Text overlays, semi-transparent panels\n",
      "\\nğŸ“Š Final image ready: (1024, 576), RGB mode\n"
     ]
    }
   ],
   "source": [
    "# SUB-AGENT 5: Post-Processor\n",
    "# Enhances and finalizes the image\n",
    "\n",
    "def post_processor_agent(img, elements_added, metadata):\n",
    "    \"\"\"\n",
    "    Agent 5: Post-processes the complete scene for final output\n",
    "    \n",
    "    Input: PIL Image (from Agent 4), List (elements), Dictionary (metadata)\n",
    "    Output: PIL Image (final enhanced image), List (elements)\n",
    "    \"\"\"\n",
    "    \n",
    "    original_prompt = metadata.get(\"original_prompt\", \"Scene\")\n",
    "    time_of_day = metadata.get(\"time\", \"day\")\n",
    "    width, height = img.size\n",
    "    \n",
    "    # Apply smoothing filter\n",
    "    img = img.filter(ImageFilter.SMOOTH_MORE)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(1.15)\n",
    "    \n",
    "    # Enhance sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(1.2)\n",
    "    \n",
    "    # Add text overlays\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font_title = ImageFont.truetype(\"arial.ttf\", 28)\n",
    "        font_desc = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except:\n",
    "        font_title = ImageFont.load_default()\n",
    "        font_desc = ImageFont.load_default()\n",
    "    \n",
    "    # Create semi-transparent overlay\n",
    "    overlay = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
    "    overlay_draw = ImageDraw.Draw(overlay)\n",
    "    overlay_draw.rectangle([10, 10, width-10, 80], fill=(0, 0, 0, 160))\n",
    "    overlay_draw.rectangle([10, height-60, width-10, height-10], fill=(0, 0, 0, 160))\n",
    "    \n",
    "    img = img.convert('RGBA')\n",
    "    img = Image.alpha_composite(img, overlay)\n",
    "    img = img.convert('RGB')\n",
    "    \n",
    "    # Add text\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    is_dark = time_of_day == \"night\"\n",
    "    title_color = (255, 255, 100) if is_dark else (255, 80, 80)\n",
    "    draw.text((20, 20), original_prompt[:70].upper(), fill=title_color, font=font_title)\n",
    "    \n",
    "    if elements_added:\n",
    "        elements_text = \" | \".join(elements_added)\n",
    "        draw.text((20, height-45), f\"ğŸ¯ {elements_text}\", fill=(100, 255, 150), font=font_desc)\n",
    "    \n",
    "    print(\"âœ… AGENT 5 (Post-Processor) - Completed\")\n",
    "    print(f\"   Applied: Smoothing, Contrast (1.15x), Sharpness (1.2x)\")\n",
    "    print(f\"   Added: Text overlays, semi-transparent panels\")\n",
    "    \n",
    "    return img, elements_added\n",
    "\n",
    "# Test the agent\n",
    "if 'test_with_effects' in dir():\n",
    "    test_final, test_elements_final = post_processor_agent(\n",
    "        test_with_effects, test_elements_updated, test_metadata)\n",
    "    print(f\"\\\\nğŸ“Š Final image ready: {test_final.size}, {test_final.mode} mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50317ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AGENT 6 (Storage Manager) - Completed\n",
      "   Saved: outputs\\custom_scene_1765037944.png\n",
      "   Size: 1024Ã—576 pixels\n",
      "   Elements: 4 items\n",
      "\\nğŸ“Š File saved: outputs\\custom_scene_1765037944.png\n"
     ]
    }
   ],
   "source": [
    "# SUB-AGENT 6: Storage Manager\n",
    "# Saves and displays the final image\n",
    "\n",
    "def storage_manager_agent(img, elements_added, metadata):\n",
    "    \"\"\"\n",
    "    Agent 6: Saves final image and manages output display\n",
    "    \n",
    "    Input: PIL Image (from Agent 5), List (elements), Dictionary (metadata)\n",
    "    Output: String (file path), Display output\n",
    "    \"\"\"\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = int(time.time())\n",
    "    img_path = os.path.join(\"outputs\", f\"custom_scene_{timestamp}.png\")\n",
    "    \n",
    "    # Save image\n",
    "    img.save(img_path, quality=95)\n",
    "    \n",
    "    # Prepare display output\n",
    "    original_prompt = metadata.get(\"original_prompt\", \"Unknown\")\n",
    "    \n",
    "    print(\"âœ… AGENT 6 (Storage Manager) - Completed\")\n",
    "    print(f\"   Saved: {img_path}\")\n",
    "    print(f\"   Size: {img.size[0]}Ã—{img.size[1]} pixels\")\n",
    "    print(f\"   Elements: {len(elements_added)} items\")\n",
    "    \n",
    "    return img_path, elements_added\n",
    "\n",
    "# Test the agent\n",
    "if 'test_final' in dir():\n",
    "    test_path, test_elements = storage_manager_agent(\n",
    "        test_final, test_elements_final, test_metadata)\n",
    "    print(f\"\\\\nğŸ“Š File saved: {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b201dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nğŸ§ª Testing Main SDG Orchestrator Agent...\\n\n",
      "\\n======================================================================\n",
      "ğŸ¤– SDG ORCHESTRATOR - Starting Multi-Agent Pipeline\n",
      "======================================================================\n",
      "ğŸ“ Input Prompt: \"A foggy street at night with a blue robot, cars, and emergency lights\"\\n\n",
      "ğŸ”„ STEP 1/6: Analyzing prompt...\n",
      "âœ… AGENT 1 (Prompt Analyzer) - Completed\n",
      "   Detected: Time=night, Weather=fog, Location=street\n",
      "   Objects: robot, vehicle\n",
      "\n",
      "ğŸ”„ STEP 2/6: Composing base scene...\n",
      "âœ… AGENT 2 (Scene Composer) - Completed\n",
      "   Created: 1024Ã—576 canvas with street environment\n",
      "   Applied: night lighting, background gradients, ground textures\n",
      "\n",
      "ğŸ”„ STEP 3/6: Rendering objects...\n",
      "âœ… AGENT 3 (Object Renderer) - Completed\n",
      "   Rendered: ğŸ¤– Robot, ğŸš— 1 Vehicle(s)\n",
      "\n",
      "ğŸ”„ STEP 4/6: Applying environmental effects...\n",
      "âœ… AGENT 4 (Environmental Effects) - Completed\n",
      "   Applied: Weather=fog, Time=night\n",
      "   Effects: ğŸŒ«ï¸ Fog, ğŸŒ™ Night Lighting, ğŸš¨ Emergency Lights\n",
      "\n",
      "ğŸ”„ STEP 5/6: Post-processing image...\n",
      "âœ… AGENT 5 (Post-Processor) - Completed\n",
      "   Applied: Smoothing, Contrast (1.15x), Sharpness (1.2x)\n",
      "   Added: Text overlays, semi-transparent panels\n",
      "\n",
      "ğŸ”„ STEP 6/6: Saving image...\n",
      "âœ… AGENT 6 (Storage Manager) - Completed\n",
      "   Saved: outputs\\custom_scene_1765037951.png\n",
      "   Size: 1024Ã—576 pixels\n",
      "   Elements: 5 items\n",
      "\n",
      "======================================================================\n",
      "âœ… SDG ORCHESTRATOR - Pipeline Complete!\n",
      "ğŸ“‚ Output: outputs\\custom_scene_1765037951.png\n",
      "ğŸ¯ Elements: ğŸ¤– Robot, ğŸš— 1 Vehicle(s), ğŸŒ«ï¸ Fog, ğŸŒ™ Night Lighting, ğŸš¨ Emergency Lights\n",
      "======================================================================\\n\n",
      "\\nâœ… Test complete! Generated: outputs\\custom_scene_1765037951.png\n"
     ]
    }
   ],
   "source": [
    "# MAIN AGENT: SDG Orchestrator\n",
    "# Coordinates all 6 sub-agents in sequence\n",
    "\n",
    "def sdg_orchestrator_agent(user_prompt):\n",
    "    \"\"\"\n",
    "    MAIN AGENT: Synthetic Data Generator Orchestrator\n",
    "    Coordinates all sub-agents to generate synthetic images\n",
    "    \n",
    "    Input: String (user prompt)\n",
    "    Output: Tuple (file_path, image, elements, metadata)\n",
    "    \n",
    "    Sequential Pipeline:\n",
    "    1. Prompt Analyzer    â†’ Extract metadata\n",
    "    2. Scene Composer     â†’ Create base canvas\n",
    "    3. Object Renderer    â†’ Add objects\n",
    "    4. Environmental FX   â†’ Apply weather/lighting\n",
    "    5. Post-Processor     â†’ Enhance image\n",
    "    6. Storage Manager    â†’ Save and display\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ¤– SDG ORCHESTRATOR - Starting Multi-Agent Pipeline\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ğŸ“ Input Prompt: \\\"{user_prompt}\\\"\\\\n\")\n",
    "    \n",
    "    # STEP 1: Analyze prompt\n",
    "    print(\"ğŸ”„ STEP 1/6: Analyzing prompt...\")\n",
    "    metadata = prompt_analyzer_agent(user_prompt)\n",
    "    print()\n",
    "    \n",
    "    # STEP 2: Compose base scene\n",
    "    print(\"ğŸ”„ STEP 2/6: Composing base scene...\")\n",
    "    canvas, metadata = scene_composer_agent(metadata)\n",
    "    print()\n",
    "    \n",
    "    # STEP 3: Render objects\n",
    "    print(\"ğŸ”„ STEP 3/6: Rendering objects...\")\n",
    "    canvas_with_objects, elements, metadata = object_renderer_agent(canvas, metadata)\n",
    "    print()\n",
    "    \n",
    "    # STEP 4: Apply environmental effects\n",
    "    print(\"ğŸ”„ STEP 4/6: Applying environmental effects...\")\n",
    "    canvas_with_effects, elements, metadata = environmental_effects_agent(\n",
    "        canvas_with_objects, elements, metadata)\n",
    "    print()\n",
    "    \n",
    "    # STEP 5: Post-process image\n",
    "    print(\"ğŸ”„ STEP 5/6: Post-processing image...\")\n",
    "    final_image, elements = post_processor_agent(canvas_with_effects, elements, metadata)\n",
    "    print()\n",
    "    \n",
    "    # STEP 6: Save and manage storage\n",
    "    print(\"ğŸ”„ STEP 6/6: Saving image...\")\n",
    "    file_path, elements = storage_manager_agent(final_image, elements, metadata)\n",
    "    print()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"âœ… SDG ORCHESTRATOR - Pipeline Complete!\")\n",
    "    print(f\"ğŸ“‚ Output: {file_path}\")\n",
    "    print(f\"ğŸ¯ Elements: {', '.join(elements)}\")\n",
    "    print(\"=\"*70 + \"\\\\n\")\n",
    "    \n",
    "    return file_path, final_image, elements, metadata\n",
    "\n",
    "# Test the main orchestrator\n",
    "test_orchestrator_prompt = \"A foggy street at night with a blue robot, cars, and emergency lights\"\n",
    "print(\"\\\\nğŸ§ª Testing Main SDG Orchestrator Agent...\\\\n\")\n",
    "test_result = sdg_orchestrator_agent(test_orchestrator_prompt)\n",
    "print(f\"\\\\nâœ… Test complete! Generated: {test_result[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ğŸ¨ Synthetic Data Generator - Multi-Agent Interface"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## ğŸ“ How It Works\n",
       "\n",
       "When you click **Generate**, the system runs a **6-agent pipeline**:\n",
       "\n",
       "1. **Prompt Analyzer** â†’ Extracts metadata (time, weather, objects)\n",
       "2. **Scene Composer** â†’ Creates base canvas with environment\n",
       "3. **Object Renderer** â†’ Draws robots, vehicles, humans, packages\n",
       "4. **Environmental Effects** â†’ Adds fog, rain, lighting, atmosphere\n",
       "5. **Post-Processor** â†’ Enhances quality with filters\n",
       "6. **Storage Manager** â†’ Saves to `outputs/` folder\n",
       "\n",
       "**All agents work sequentially, passing data from one to the next!**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ğŸ“ Enter Your Scene Description"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e911a6fee8a4dcc8fdca8c61ce2c890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='A foggy street at night with a blue robot, cars, and emergency lights', descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefe2b17c28a4f8d9476e9366317a408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "## ğŸ’¡ Example Prompts\n",
       "\n",
       "**Multi-Element Scenes:**\n",
       "- *\"A foggy street at night with a blue robot, cars, and emergency lights\"*\n",
       "- *\"A busy warehouse with packages, orange robot, and workers in safety vests\"*\n",
       "- *\"A rainy parking lot at sunset with a delivery truck and a cat\"*\n",
       "\n",
       "**Weather Variations:**\n",
       "- *\"A snowy street at night with street lamps and a yellow robot\"*\n",
       "- *\"A foggy intersection with multiple vehicles and pedestrians\"*\n",
       "\n",
       "**Complex Scenarios:**\n",
       "- *\"A busy street at night with rain, emergency lights, cars, and a drone hovering\"*\n",
       "\n",
       "**Key Elements:**\n",
       "- ğŸ¤– Objects: robot, drone, car, truck, package, person, worker, cat, dog\n",
       "- ğŸŒ¤ï¸ Weather: fog, rain, snow, clear\n",
       "- ğŸ• Time: night, sunset, day\n",
       "- ğŸ“ Location: street, warehouse, parking\n",
       "- ğŸ¨ Colors: yellow, blue, orange, red\n",
       "- âš ï¸ Special: emergency, safety vest, busy\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nâœ… Interactive UI ready!\n",
      "ğŸ‘† Enter your prompt above and click 'Generate with SDG Agent'\n",
      "ğŸ“Š Watch the console for real-time agent pipeline progress!\n"
     ]
    }
   ],
   "source": [
    "# Interactive UI Controller\n",
    "# Connects user interface to the main SDG Orchestrator\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "text_input = widgets.Textarea(\n",
    "    value='A foggy street at night with a blue robot, cars, and emergency lights',\n",
    "    placeholder='Describe your scene in detail...',\n",
    "    description='Scene:',\n",
    "    layout=widgets.Layout(width='95%', height='120px'),\n",
    "    style={'description_width': '60px'}\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description='ğŸ¨ Generate with SDG Agent',\n",
    "    button_style='success',\n",
    "    tooltip='Runs complete multi-agent pipeline',\n",
    "    icon='cogs',\n",
    "    layout=widgets.Layout(width='280px', height='50px')\n",
    ")\n",
    "\n",
    "def on_generate_click(b):\n",
    "    \"\"\"Button handler - Triggers main SDG Orchestrator agent\"\"\"\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        user_prompt = text_input.value.strip()\n",
    "        \n",
    "        if not user_prompt:\n",
    "            display(Markdown(\"âš ï¸ **Please enter a scene description!**\"))\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Call main SDG Orchestrator - this runs all 6 sub-agents\n",
    "            file_path, final_img, elements, metadata = sdg_orchestrator_agent(user_prompt)\n",
    "            \n",
    "            # Display results\n",
    "            display(Markdown(f\"### âœ… Image Generated Successfully!\"))\n",
    "            display(Markdown(f\"**Prompt:** {user_prompt}\"))\n",
    "            display(Markdown(f\"ğŸ“ **Saved to:** `{file_path}`\"))\n",
    "            display(HTML(f\"<img src='{file_path}' style='max-width:95%; border-radius:12px; box-shadow:0 8px 16px rgba(0,0,0,0.3); margin:20px 0; border:3px solid #4CAF50;'>\"))\n",
    "            \n",
    "            if elements:\n",
    "                display(Markdown(f\"**ğŸ¯ Detected Elements:** {', '.join(elements)}\"))\n",
    "            \n",
    "            display(Markdown(\"---\"))\n",
    "            display(Markdown(f\"**ğŸ”„ Agent Pipeline Used:**\"))\n",
    "            display(Markdown(\"\"\"\n",
    "            1. âœ… Prompt Analyzer - Parsed scene metadata\n",
    "            2. âœ… Scene Composer - Created base canvas\n",
    "            3. âœ… Object Renderer - Drew objects\n",
    "            4. âœ… Environmental Effects - Applied weather & lighting\n",
    "            5. âœ… Post-Processor - Enhanced image quality\n",
    "            6. âœ… Storage Manager - Saved and displayed\n",
    "            \"\"\"))\n",
    "            display(Markdown(\"ğŸ’¡ **Tip:** Edit the prompt above and generate again!\"))\n",
    "            \n",
    "        except Exception as e:\n",
    "            clear_output(wait=True)\n",
    "            display(Markdown(f\"### âŒ Error: {str(e)}\"))\n",
    "            display(Markdown(\"Please try again or simplify your prompt.\"))\n",
    "\n",
    "generate_button.on_click(on_generate_click)\n",
    "\n",
    "# Display UI\n",
    "display(Markdown(\"# ğŸ¨ Synthetic Data Generator - Multi-Agent Interface\"))\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(\"\"\"\n",
    "## ğŸ“ How It Works\n",
    "\n",
    "When you click **Generate**, the system runs a **6-agent pipeline**:\n",
    "\n",
    "1. **Prompt Analyzer** â†’ Extracts metadata (time, weather, objects)\n",
    "2. **Scene Composer** â†’ Creates base canvas with environment\n",
    "3. **Object Renderer** â†’ Draws robots, vehicles, humans, packages\n",
    "4. **Environmental Effects** â†’ Adds fog, rain, lighting, atmosphere\n",
    "5. **Post-Processor** â†’ Enhances quality with filters\n",
    "6. **Storage Manager** â†’ Saves to `outputs/` folder\n",
    "\n",
    "**All agents work sequentially, passing data from one to the next!**\n",
    "\"\"\"))\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(\"## ğŸ“ Enter Your Scene Description\"))\n",
    "display(widgets.VBox([text_input, generate_button], layout=widgets.Layout(margin='15px 0')))\n",
    "display(output_area)\n",
    "\n",
    "# Show example prompts\n",
    "display(Markdown(\"\"\"\n",
    "---\n",
    "## ğŸ’¡ Example Prompts\n",
    "\n",
    "**Multi-Element Scenes:**\n",
    "- *\"A foggy street at night with a blue robot, cars, and emergency lights\"*\n",
    "- *\"A busy warehouse with packages, orange robot, and workers in safety vests\"*\n",
    "- *\"A rainy parking lot at sunset with a delivery truck and a cat\"*\n",
    "\n",
    "**Weather Variations:**\n",
    "- *\"A snowy street at night with street lamps and a yellow robot\"*\n",
    "- *\"A foggy intersection with multiple vehicles and pedestrians\"*\n",
    "\n",
    "**Complex Scenarios:**\n",
    "- *\"A busy street at night with rain, emergency lights, cars, and a drone hovering\"*\n",
    "\n",
    "**Key Elements:**\n",
    "- ğŸ¤– Objects: robot, drone, car, truck, package, person, worker, cat, dog\n",
    "- ğŸŒ¤ï¸ Weather: fog, rain, snow, clear\n",
    "- ğŸ• Time: night, sunset, day\n",
    "- ğŸ“ Location: street, warehouse, parking\n",
    "- ğŸ¨ Colors: yellow, blue, orange, red\n",
    "- âš ï¸ Special: emergency, safety vest, busy\n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\\\nâœ… Interactive UI ready!\")\n",
    "print(\"ğŸ‘† Enter your prompt above and click 'Generate with SDG Agent'\")\n",
    "print(\"ğŸ“Š Watch the console for real-time agent pipeline progress!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdd871",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 10: Interactive User Interface\n",
    "\n",
    "**Agent Name:** UI Controller Agent\n",
    "\n",
    "**Role:** Provides interactive interface for the SDG Orchestrator\n",
    "\n",
    "**What it does:**\n",
    "- Creates text input widget for user prompts\n",
    "- Provides generate button to trigger main agent\n",
    "- Displays real-time progress from all 6 sub-agents\n",
    "- Shows final image and metadata\n",
    "- Links button click to SDG Orchestrator agent\n",
    "\n",
    "**Data Flow:**\n",
    "```\n",
    "User types prompt â†’ Click Generate â†’ SDG Orchestrator (Cells 3-9) â†’ Display output\n",
    "```\n",
    "\n",
    "**Input:** User interaction (text + button click)  \n",
    "**Output:** Interactive display with generated image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbccfa14",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 9: MAIN AGENT - SDG Orchestrator\n",
    "\n",
    "**Agent Name:** Synthetic Data Generator (SDG) Orchestrator\n",
    "\n",
    "**Role:** Main coordinating agent that manages all 6 sub-agents\n",
    "\n",
    "**What it does:**\n",
    "- Receives user prompt as input\n",
    "- Orchestrates the complete pipeline sequentially\n",
    "- Passes output of each agent to the next agent's input\n",
    "- Manages data flow between all sub-agents\n",
    "- Returns final image and metadata\n",
    "\n",
    "**Pipeline Flow:**\n",
    "```\n",
    "User Prompt (Input)\n",
    "    â†“\n",
    "Agent 1: Prompt Analyzer â†’ metadata\n",
    "    â†“\n",
    "Agent 2: Scene Composer â†’ canvas + metadata\n",
    "    â†“\n",
    "Agent 3: Object Renderer â†’ canvas with objects + elements + metadata\n",
    "    â†“\n",
    "Agent 4: Environmental Effects â†’ canvas with effects + elements + metadata\n",
    "    â†“\n",
    "Agent 5: Post-Processor â†’ final image + elements\n",
    "    â†“\n",
    "Agent 6: Storage Manager â†’ saved file path + display\n",
    "    â†“\n",
    "Final Output (Image + Metadata)\n",
    "```\n",
    "\n",
    "**Input:** String (user description)  \n",
    "**Output:** String (file path), PIL Image, List (elements), Dictionary (metadata)\n",
    "\n",
    "**Time:** 1-3 seconds (complete pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c2ec6",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 8: Sub-Agent 6 - Storage Manager\n",
    "\n",
    "**Agent Name:** File Storage & Display Manager\n",
    "\n",
    "**Role in Pipeline:** Receives final image from Agent 5\n",
    "\n",
    "**What it does:**\n",
    "- Takes finalized image from post-processor\n",
    "- Generates timestamp-based filename\n",
    "- Saves image to `outputs/` directory\n",
    "- Creates HTML display output\n",
    "- Shows detected elements list\n",
    "- Returns confirmation and file path\n",
    "\n",
    "**Input:** PIL Image (from Agent 5) + Elements list  \n",
    "**Output:** Saved file path + Display confirmation\n",
    "\n",
    "**Data Flow:**\n",
    "```\n",
    "Agent 5 Output â†’ Agent 6 Input\n",
    "Final image â†’ Saved as outputs/custom_scene_1234567890.png + displayed\n",
    "```\n",
    "\n",
    "**Time:** 0.05-0.1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6986e",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 7: Sub-Agent 5 - Post-Processor\n",
    "\n",
    "**Agent Name:** Image Post-Processing Agent\n",
    "\n",
    "**Role in Pipeline:** Receives complete scene from Agent 4\n",
    "\n",
    "**What it does:**\n",
    "- Takes fully composed image with all elements\n",
    "- Applies smoothing filters for realism\n",
    "- Enhances contrast (1.15x boost)\n",
    "- Sharpens image (1.2x adjustment)\n",
    "- Adds semi-transparent overlays\n",
    "- Creates text annotations with scene info\n",
    "- Prepares final image for output\n",
    "\n",
    "**Input:** PIL Image (from Agent 4) + Elements list + Metadata  \n",
    "**Output:** PIL Image (final polished image) + Elements list\n",
    "\n",
    "**Data Flow:**\n",
    "```\n",
    "Agent 4 Output â†’ Agent 5 Input\n",
    "Complete scene â†’ Filtered, enhanced, annotated final image\n",
    "```\n",
    "\n",
    "**Time:** 0.1-0.3 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9710241",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 6: Sub-Agent 4 - Environmental Effects\n",
    "\n",
    "**Agent Name:** Environmental Effects Processor\n",
    "\n",
    "**Role in Pipeline:** Receives canvas with objects from Agent 3\n",
    "\n",
    "**What it does:**\n",
    "- Takes canvas with rendered objects\n",
    "- Applies weather effects (fog particles, rain drops, snow)\n",
    "- Adds lighting (street lamps, emergency lights, sunset glow)\n",
    "- Creates atmospheric layers\n",
    "- Applies darkening for night scenes\n",
    "- Blends effects with existing scene\n",
    "\n",
    "**Input:** PIL Image (canvas from Agent 3) + Metadata  \n",
    "**Output:** PIL Image (canvas with environmental effects)\n",
    "\n",
    "**Data Flow:**\n",
    "```\n",
    "Agent 3 Output â†’ Agent 4 Input\n",
    "Canvas with objects + {weather: \"fog\", time: \"night\"} â†’ Canvas with fog layers + street lamps\n",
    "```\n",
    "\n",
    "**Time:** 0.3-0.7 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963143c8",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 5: Sub-Agent 3 - Object Renderer\n",
    "\n",
    "**Agent Name:** Object Rendering Engine\n",
    "\n",
    "**Role in Pipeline:** Receives canvas from Agent 2 and metadata from Agent 1\n",
    "\n",
    "**What it does:**\n",
    "- Takes canvas and metadata from previous agents\n",
    "- Renders robots/drones with color detection, shading, cameras\n",
    "- Draws vehicles with gradients, wheels, windshields, headlights\n",
    "- Creates humans with realistic proportions and safety gear\n",
    "- Adds animals (cats, dogs) with details\n",
    "- Places packages with stacking and shadows\n",
    "- Positions all objects intelligently on canvas\n",
    "\n",
    "**Input:** PIL Image (canvas from Agent 2) + Metadata  \n",
    "**Output:** PIL Image (canvas with rendered objects)\n",
    "\n",
    "**Data Flow:**\n",
    "```\n",
    "Agent 2 Output â†’ Agent 3 Input\n",
    "Base canvas + {objects: [\"robot\", \"vehicle\"]} â†’ Canvas with robot and vehicle drawn\n",
    "```\n",
    "\n",
    "**Time:** 0.5-1 second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f8f45",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 4: Sub-Agent 2 - Scene Composer\n",
    "\n",
    "**Agent Name:** Base Scene Composer\n",
    "\n",
    "**Role in Pipeline:** Receives metadata from Agent 1\n",
    "\n",
    "**What it does:**\n",
    "- Takes metadata dictionary from Prompt Analyzer\n",
    "- Creates base canvas (1024Ã—576 pixels)\n",
    "- Determines color scheme based on time and weather\n",
    "- Applies gradient background\n",
    "- Adds ground textures (street, warehouse, parking)\n",
    "- Prepares canvas for object placement\n",
    "\n",
    "**Input:** Metadata dictionary from Agent 1  \n",
    "**Output:** PIL Image object with base scene\n",
    "\n",
    "**Data Flow:**\n",
    "```\n",
    "Agent 1 Output â†’ Agent 2 Input\n",
    "{time: \"night\", weather: \"fog\"} â†’ Dark blue gradient + fog-colored background\n",
    "```\n",
    "\n",
    "**Time:** 0.2-0.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79d238",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Cell 3: Sub-Agent 1 - Prompt Analyzer\n",
    "\n",
    "**Agent Name:** Natural Language Prompt Analyzer\n",
    "\n",
    "**Role in Pipeline:** First agent in the SDG workflow\n",
    "\n",
    "**What it does:**\n",
    "- Receives raw text description from user\n",
    "- Performs NLP analysis to extract scene attributes\n",
    "- Detects time of day (night, sunset, day)\n",
    "- Identifies weather conditions (fog, rain, snow, clear)\n",
    "- Determines location type (street, warehouse, parking)\n",
    "- Extracts object mentions (robot, car, person, package)\n",
    "- Creates structured metadata dictionary\n",
    "\n",
    "**Input:** String (user prompt)  \n",
    "**Output:** Dictionary with scene metadata\n",
    "\n",
    "**Example Flow:**\n",
    "```\n",
    "Input: \"A foggy street at night with a blue robot and cars\"\n",
    "â†“\n",
    "Processing: Parse keywords, detect attributes\n",
    "â†“\n",
    "Output: {\n",
    "  \"time\": \"night\",\n",
    "  \"weather\": \"fog\",\n",
    "  \"location\": \"street\",\n",
    "  \"objects\": [\"robot\", \"car\"],\n",
    "  \"colors\": [\"blue\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**Time:** <0.1 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
